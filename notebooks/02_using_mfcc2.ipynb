{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88a7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6923c",
   "metadata": {},
   "source": [
    "#### Setting path to RAVDESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba31be2",
   "metadata": {},
   "source": [
    "Modality-VocalChannel-Emotion-Intensity-Statement-Repetition-Actor.wav\n",
    "\n",
    "03-01-05-01-02-02-12.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e427e1",
   "metadata": {},
   "source": [
    "we'll only keep 01, 03, 04, 05, 06, 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3f4ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/ravdess\\Actor_01\\03-01-01-01-01-01...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/ravdess\\Actor_01\\03-01-01-01-01-02...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/ravdess\\Actor_01\\03-01-01-01-02-01...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/ravdess\\Actor_01\\03-01-01-01-02-02...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/ravdess\\Actor_01\\03-01-03-01-01-01...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  emotion\n",
       "0  ../datasets/ravdess\\Actor_01\\03-01-01-01-01-01...  neutral\n",
       "1  ../datasets/ravdess\\Actor_01\\03-01-01-01-01-02...  neutral\n",
       "2  ../datasets/ravdess\\Actor_01\\03-01-01-01-02-01...  neutral\n",
       "3  ../datasets/ravdess\\Actor_01\\03-01-01-01-02-02...  neutral\n",
       "4  ../datasets/ravdess\\Actor_01\\03-01-03-01-01-01...    happy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"../datasets/ravdess\"\n",
    "\n",
    "emotion_map = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\"\n",
    "}\n",
    "\n",
    "file_paths = []\n",
    "emotions = []\n",
    "\n",
    "for root, dirs, files in os.walk(DATA_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            emotion_code = file.split(\"-\")[2]\n",
    "            \n",
    "            if emotion_code in emotion_map:\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "                emotions.append(emotion_map[emotion_code])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"path\": file_paths,\n",
    "    \"emotion\": emotions\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30f7066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "happy      192\n",
       "sad        192\n",
       "angry      192\n",
       "fearful    192\n",
       "disgust    192\n",
       "neutral     96\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452250ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1056\n"
     ]
    }
   ],
   "source": [
    "print(\"Total samples:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665f85a",
   "metadata": {},
   "source": [
    "### Audio standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c0ef3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3 \n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "def load_audio(file_path):\n",
    "    signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "    \n",
    "    if len(signal) > SAMPLES_PER_TRACK:\n",
    "        signal = signal[:SAMPLES_PER_TRACK]\n",
    "    else:\n",
    "        padding = SAMPLES_PER_TRACK - len(signal)\n",
    "        signal = np.pad(signal, (0, padding))\n",
    "        \n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba34c25",
   "metadata": {},
   "source": [
    "### Extract MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6807e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(signal, sr=SAMPLE_RATE, n_mfcc=40):\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y=signal,\n",
    "        sr=sr,\n",
    "        n_mfcc=n_mfcc,\n",
    "        n_fft=2048,\n",
    "        hop_length=512\n",
    "    )\n",
    "    \n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    \n",
    "    combined = np.stack((mfcc, delta, delta2), axis=-1)\n",
    "    \n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91c8569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC shape: (40, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "sample_signal = load_audio(df[\"path\"].iloc[0])\n",
    "mfcc = extract_mfcc(sample_signal)\n",
    "\n",
    "print(\"MFCC shape:\", mfcc.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b16f8",
   "metadata": {},
   "source": [
    "### Encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c679c9",
   "metadata": {},
   "source": [
    "Actor column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1af29b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"actor\"] = df[\"path\"].apply(\n",
    "    lambda x: x.split(\"-\")[-1].replace(\".wav\", \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c8a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"emotion\"])\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "\n",
    "train_idx, test_idx = next(\n",
    "    gss.split(df, df[\"label\"], groups=df[\"actor\"])\n",
    ")\n",
    "\n",
    "train_df = df.iloc[train_idx]\n",
    "test_df = df.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d2bdb",
   "metadata": {},
   "source": [
    "### Speaker-based Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff58898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "\n",
    "train_idx, test_idx = next(\n",
    "    gss.split(df, df[\"label\"], groups=df[\"actor\"])\n",
    ")\n",
    "\n",
    "train_df = df.iloc[train_idx]\n",
    "test_df = df.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fc21d2",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91160213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (836, 40, 130, 3)\n",
      "Test shape: (220, 40, 130, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "\n",
    "# Training set\n",
    "for _, row in train_df.iterrows():\n",
    "    signal = load_audio(row[\"path\"])\n",
    "    features = extract_mfcc(signal)\n",
    "    X_train.append(features)\n",
    "    y_train.append(row[\"label\"])\n",
    "\n",
    "# Test set\n",
    "for _, row in test_df.iterrows():\n",
    "    signal = load_audio(row[\"path\"])\n",
    "    features = extract_mfcc(signal)\n",
    "    X_test.append(features)\n",
    "    y_test.append(row[\"label\"])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380a30d",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0f2526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train)\n",
    "std = np.std(X_train)\n",
    "\n",
    "X_train = (X_train - mean) / (std + 1e-8)\n",
    "X_test = (X_test - mean) / (std + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15769974",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257be734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ee9ce",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a582e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vivek\\Videos\\Audio-based-Emotion-Classifier-\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20480</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,243,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20480\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m5,243,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,542\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,617,286</span> (21.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,617,286\u001b[0m (21.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,616,390</span> (21.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,616,390\u001b[0m (21.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, BatchNormalization,\n",
    "    Flatten, Dense, Dropout\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffcefc3",
   "metadata": {},
   "source": [
    "#### Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82da674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=4,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',      # watch validation loss\n",
    "    patience=8,              # wait 8 epochs before stopping\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "813d109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: np.float64(0.9166666666666666), 1: np.float64(0.9166666666666666), 2: np.float64(0.9166666666666666), 3: np.float64(0.9166666666666666), 4: np.float64(1.8333333333333333), 5: np.float64(0.9166666666666666)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "    y=np.argmax(y_train, axis=1)\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd928e",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16658e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 538ms/step - accuracy: 0.2093 - loss: 3.3865 - val_accuracy: 0.0909 - val_loss: 1.8067\n",
      "Epoch 2/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.2524 - loss: 1.7658 - val_accuracy: 0.0909 - val_loss: 1.8252\n",
      "Epoch 3/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 526ms/step - accuracy: 0.2883 - loss: 1.6646 - val_accuracy: 0.1318 - val_loss: 1.8433\n",
      "Epoch 4/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 526ms/step - accuracy: 0.2907 - loss: 1.6354 - val_accuracy: 0.1364 - val_loss: 1.8469\n",
      "Epoch 5/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 531ms/step - accuracy: 0.3158 - loss: 1.6035 - val_accuracy: 0.1727 - val_loss: 1.8125\n",
      "Epoch 6/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 527ms/step - accuracy: 0.3349 - loss: 1.5718 - val_accuracy: 0.1727 - val_loss: 1.8373\n",
      "Epoch 7/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 532ms/step - accuracy: 0.3242 - loss: 1.5845 - val_accuracy: 0.1818 - val_loss: 1.8110\n",
      "Epoch 8/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 536ms/step - accuracy: 0.3828 - loss: 1.5104 - val_accuracy: 0.2273 - val_loss: 1.8023\n",
      "Epoch 9/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 562ms/step - accuracy: 0.3660 - loss: 1.5265 - val_accuracy: 0.2864 - val_loss: 1.7608\n",
      "Epoch 10/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 551ms/step - accuracy: 0.3553 - loss: 1.5033 - val_accuracy: 0.2636 - val_loss: 1.7485\n",
      "Epoch 11/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 552ms/step - accuracy: 0.3911 - loss: 1.4633 - val_accuracy: 0.2682 - val_loss: 1.7043\n",
      "Epoch 12/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 572ms/step - accuracy: 0.3768 - loss: 1.4163 - val_accuracy: 0.2591 - val_loss: 1.6665\n",
      "Epoch 13/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 574ms/step - accuracy: 0.4246 - loss: 1.3584 - val_accuracy: 0.2682 - val_loss: 1.7021\n",
      "Epoch 14/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 569ms/step - accuracy: 0.4211 - loss: 1.3595 - val_accuracy: 0.2773 - val_loss: 1.7054\n",
      "Epoch 15/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 621ms/step - accuracy: 0.4450 - loss: 1.3073 - val_accuracy: 0.3318 - val_loss: 1.6683\n",
      "Epoch 16/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 695ms/step - accuracy: 0.4366 - loss: 1.3438 - val_accuracy: 0.2955 - val_loss: 1.6165\n",
      "Epoch 17/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 637ms/step - accuracy: 0.4462 - loss: 1.2902 - val_accuracy: 0.2591 - val_loss: 1.6516\n",
      "Epoch 18/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 606ms/step - accuracy: 0.4809 - loss: 1.2835 - val_accuracy: 0.2636 - val_loss: 1.6323\n",
      "Epoch 19/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 602ms/step - accuracy: 0.4713 - loss: 1.2791 - val_accuracy: 0.2818 - val_loss: 1.6302\n",
      "Epoch 20/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 606ms/step - accuracy: 0.4916 - loss: 1.2222 - val_accuracy: 0.3227 - val_loss: 1.5482\n",
      "Epoch 21/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 603ms/step - accuracy: 0.5072 - loss: 1.1890 - val_accuracy: 0.3000 - val_loss: 1.6011\n",
      "Epoch 22/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 691ms/step - accuracy: 0.5024 - loss: 1.1732 - val_accuracy: 0.3318 - val_loss: 1.6286\n",
      "Epoch 23/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 636ms/step - accuracy: 0.5299 - loss: 1.1105 - val_accuracy: 0.3500 - val_loss: 1.5793\n",
      "Epoch 24/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 627ms/step - accuracy: 0.5383 - loss: 1.1341 - val_accuracy: 0.3545 - val_loss: 1.5436\n",
      "Epoch 25/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 618ms/step - accuracy: 0.5514 - loss: 1.1263 - val_accuracy: 0.3682 - val_loss: 1.6065\n",
      "Epoch 26/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 597ms/step - accuracy: 0.5562 - loss: 1.0969 - val_accuracy: 0.3455 - val_loss: 1.6299\n",
      "Epoch 27/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 549ms/step - accuracy: 0.5610 - loss: 1.0845 - val_accuracy: 0.3636 - val_loss: 1.5753\n",
      "Epoch 28/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 531ms/step - accuracy: 0.5455 - loss: 1.0745 - val_accuracy: 0.4182 - val_loss: 1.4857\n",
      "Epoch 29/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 552ms/step - accuracy: 0.6005 - loss: 1.0118 - val_accuracy: 0.4045 - val_loss: 1.5112\n",
      "Epoch 30/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 637ms/step - accuracy: 0.5945 - loss: 1.0254 - val_accuracy: 0.3955 - val_loss: 1.5033\n",
      "Epoch 31/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 535ms/step - accuracy: 0.5646 - loss: 1.0367 - val_accuracy: 0.3500 - val_loss: 1.6924\n",
      "Epoch 32/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 532ms/step - accuracy: 0.5909 - loss: 1.0173 - val_accuracy: 0.3636 - val_loss: 1.6006\n",
      "Epoch 33/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 536ms/step - accuracy: 0.6328 - loss: 0.9639 - val_accuracy: 0.3864 - val_loss: 1.7111\n",
      "Epoch 34/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 566ms/step - accuracy: 0.6065 - loss: 0.9417 - val_accuracy: 0.3545 - val_loss: 1.8006\n",
      "Epoch 35/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 565ms/step - accuracy: 0.6268 - loss: 0.9516 - val_accuracy: 0.4091 - val_loss: 1.6160\n",
      "Epoch 36/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 536ms/step - accuracy: 0.6208 - loss: 0.8890 - val_accuracy: 0.4182 - val_loss: 1.6322\n",
      "Epoch 37/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 585ms/step - accuracy: 0.6447 - loss: 0.8762 - val_accuracy: 0.4136 - val_loss: 1.5594\n",
      "Epoch 38/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 588ms/step - accuracy: 0.6519 - loss: 0.8614 - val_accuracy: 0.3773 - val_loss: 1.7036\n",
      "Epoch 39/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 558ms/step - accuracy: 0.6507 - loss: 0.8448 - val_accuracy: 0.4364 - val_loss: 1.5162\n",
      "Epoch 40/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 523ms/step - accuracy: 0.6639 - loss: 0.8307 - val_accuracy: 0.4045 - val_loss: 1.5751\n",
      "Epoch 41/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 520ms/step - accuracy: 0.6675 - loss: 0.8452 - val_accuracy: 0.4227 - val_loss: 1.6270\n",
      "Epoch 42/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.6555 - loss: 0.8353 - val_accuracy: 0.4273 - val_loss: 1.4467\n",
      "Epoch 43/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 518ms/step - accuracy: 0.6663 - loss: 0.7653 - val_accuracy: 0.4227 - val_loss: 1.5609\n",
      "Epoch 44/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.6722 - loss: 0.7890 - val_accuracy: 0.4000 - val_loss: 1.5677\n",
      "Epoch 45/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.6758 - loss: 0.7926 - val_accuracy: 0.4364 - val_loss: 1.6095\n",
      "Epoch 46/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 530ms/step - accuracy: 0.7057 - loss: 0.7530 - val_accuracy: 0.4682 - val_loss: 1.5598\n",
      "Epoch 47/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.7033 - loss: 0.7497 - val_accuracy: 0.4500 - val_loss: 1.5922\n",
      "Epoch 48/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.7273 - loss: 0.6812 - val_accuracy: 0.4545 - val_loss: 1.6142\n",
      "Epoch 49/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 518ms/step - accuracy: 0.7033 - loss: 0.7219 - val_accuracy: 0.4545 - val_loss: 1.5432\n",
      "Epoch 50/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 524ms/step - accuracy: 0.7177 - loss: 0.6574 - val_accuracy: 0.4818 - val_loss: 1.5776\n",
      "Epoch 51/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 527ms/step - accuracy: 0.7153 - loss: 0.6993 - val_accuracy: 0.4955 - val_loss: 1.3803\n",
      "Epoch 52/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.7117 - loss: 0.6798 - val_accuracy: 0.4864 - val_loss: 1.3872\n",
      "Epoch 53/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 520ms/step - accuracy: 0.7464 - loss: 0.6394 - val_accuracy: 0.4773 - val_loss: 1.4998\n",
      "Epoch 54/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.7548 - loss: 0.5890 - val_accuracy: 0.4682 - val_loss: 1.7694\n",
      "Epoch 55/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 523ms/step - accuracy: 0.7632 - loss: 0.5931 - val_accuracy: 0.4864 - val_loss: 1.6549\n",
      "Epoch 56/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 519ms/step - accuracy: 0.7739 - loss: 0.5899 - val_accuracy: 0.4818 - val_loss: 1.5339\n",
      "Epoch 57/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 523ms/step - accuracy: 0.8002 - loss: 0.5422 - val_accuracy: 0.4909 - val_loss: 1.5018\n",
      "Epoch 58/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 519ms/step - accuracy: 0.7799 - loss: 0.5429 - val_accuracy: 0.4818 - val_loss: 1.5426\n",
      "Epoch 59/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.7656 - loss: 0.5589 - val_accuracy: 0.4864 - val_loss: 1.5265\n",
      "Epoch 60/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 554ms/step - accuracy: 0.7644 - loss: 0.6090 - val_accuracy: 0.5045 - val_loss: 1.4512\n",
      "Epoch 61/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 519ms/step - accuracy: 0.8014 - loss: 0.5205 - val_accuracy: 0.4909 - val_loss: 1.6230\n",
      "Epoch 62/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.8170 - loss: 0.4830 - val_accuracy: 0.4818 - val_loss: 1.5572\n",
      "Epoch 63/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.8134 - loss: 0.4771 - val_accuracy: 0.4636 - val_loss: 1.6090\n",
      "Epoch 64/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 529ms/step - accuracy: 0.8122 - loss: 0.4859 - val_accuracy: 0.4727 - val_loss: 1.6033\n",
      "Epoch 65/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 537ms/step - accuracy: 0.8289 - loss: 0.4509 - val_accuracy: 0.4909 - val_loss: 1.6023\n",
      "Epoch 66/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 530ms/step - accuracy: 0.8433 - loss: 0.4261 - val_accuracy: 0.5045 - val_loss: 1.6199\n",
      "Epoch 67/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 524ms/step - accuracy: 0.8313 - loss: 0.4329 - val_accuracy: 0.5091 - val_loss: 1.6823\n",
      "Epoch 68/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.8361 - loss: 0.4233 - val_accuracy: 0.4727 - val_loss: 1.6697\n",
      "Epoch 69/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 526ms/step - accuracy: 0.8589 - loss: 0.3881 - val_accuracy: 0.4864 - val_loss: 1.6928\n",
      "Epoch 70/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.8373 - loss: 0.4349 - val_accuracy: 0.4909 - val_loss: 1.6961\n",
      "Epoch 71/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 608ms/step - accuracy: 0.8409 - loss: 0.4245 - val_accuracy: 0.4591 - val_loss: 1.9235\n",
      "Epoch 72/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 584ms/step - accuracy: 0.8397 - loss: 0.4161 - val_accuracy: 0.4682 - val_loss: 1.9381\n",
      "Epoch 73/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 565ms/step - accuracy: 0.8409 - loss: 0.4137 - val_accuracy: 0.4909 - val_loss: 1.5381\n",
      "Epoch 74/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 585ms/step - accuracy: 0.8624 - loss: 0.3833 - val_accuracy: 0.4955 - val_loss: 1.7858\n",
      "Epoch 75/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 538ms/step - accuracy: 0.8397 - loss: 0.4240 - val_accuracy: 0.5136 - val_loss: 1.6366\n",
      "Epoch 76/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 527ms/step - accuracy: 0.8612 - loss: 0.3535 - val_accuracy: 0.5045 - val_loss: 1.9159\n",
      "Epoch 77/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 554ms/step - accuracy: 0.8636 - loss: 0.3685 - val_accuracy: 0.4909 - val_loss: 1.7158\n",
      "Epoch 78/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 544ms/step - accuracy: 0.8768 - loss: 0.3072 - val_accuracy: 0.4591 - val_loss: 2.0410\n",
      "Epoch 79/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 532ms/step - accuracy: 0.8756 - loss: 0.3332 - val_accuracy: 0.5136 - val_loss: 2.0037\n",
      "Epoch 80/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 524ms/step - accuracy: 0.8792 - loss: 0.3299 - val_accuracy: 0.5273 - val_loss: 1.8388\n",
      "Epoch 81/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.8828 - loss: 0.3223 - val_accuracy: 0.4864 - val_loss: 1.7455\n",
      "Epoch 82/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 575ms/step - accuracy: 0.8780 - loss: 0.3265 - val_accuracy: 0.5318 - val_loss: 1.6487\n",
      "Epoch 83/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 626ms/step - accuracy: 0.8792 - loss: 0.3140 - val_accuracy: 0.4864 - val_loss: 1.9239\n",
      "Epoch 84/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 530ms/step - accuracy: 0.8923 - loss: 0.2932 - val_accuracy: 0.5045 - val_loss: 1.9919\n",
      "Epoch 85/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 754ms/step - accuracy: 0.8911 - loss: 0.2770 - val_accuracy: 0.5364 - val_loss: 1.7699\n",
      "Epoch 86/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 602ms/step - accuracy: 0.8840 - loss: 0.2852 - val_accuracy: 0.4909 - val_loss: 1.8558\n",
      "Epoch 87/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 546ms/step - accuracy: 0.8923 - loss: 0.2935 - val_accuracy: 0.5091 - val_loss: 1.7961\n",
      "Epoch 88/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.8923 - loss: 0.2850 - val_accuracy: 0.4864 - val_loss: 1.7642\n",
      "Epoch 89/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 520ms/step - accuracy: 0.8828 - loss: 0.2713 - val_accuracy: 0.5136 - val_loss: 1.7246\n",
      "Epoch 90/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 527ms/step - accuracy: 0.8804 - loss: 0.2800 - val_accuracy: 0.5182 - val_loss: 1.8145\n",
      "Epoch 91/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.9019 - loss: 0.2808 - val_accuracy: 0.5045 - val_loss: 1.7804\n",
      "Epoch 92/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.9294 - loss: 0.2398 - val_accuracy: 0.5136 - val_loss: 1.7724\n",
      "Epoch 93/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 519ms/step - accuracy: 0.9127 - loss: 0.2449 - val_accuracy: 0.5182 - val_loss: 1.7712\n",
      "Epoch 94/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.9055 - loss: 0.2521 - val_accuracy: 0.4955 - val_loss: 1.9589\n",
      "Epoch 95/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 520ms/step - accuracy: 0.9115 - loss: 0.2200 - val_accuracy: 0.4909 - val_loss: 2.0314\n",
      "Epoch 96/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.9342 - loss: 0.1888 - val_accuracy: 0.4864 - val_loss: 1.8277\n",
      "Epoch 97/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.9127 - loss: 0.2004 - val_accuracy: 0.4773 - val_loss: 1.9707\n",
      "Epoch 98/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.9222 - loss: 0.2147 - val_accuracy: 0.4818 - val_loss: 2.0016\n",
      "Epoch 99/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.9163 - loss: 0.2189 - val_accuracy: 0.4955 - val_loss: 1.8248\n",
      "Epoch 100/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 520ms/step - accuracy: 0.9211 - loss: 0.2105 - val_accuracy: 0.5091 - val_loss: 1.8156\n",
      "Epoch 101/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 519ms/step - accuracy: 0.9342 - loss: 0.1833 - val_accuracy: 0.5091 - val_loss: 1.8260\n",
      "Epoch 102/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.9127 - loss: 0.2229 - val_accuracy: 0.5273 - val_loss: 1.8547\n",
      "Epoch 103/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 518ms/step - accuracy: 0.9498 - loss: 0.1598 - val_accuracy: 0.5364 - val_loss: 1.9758\n",
      "Epoch 104/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 525ms/step - accuracy: 0.9354 - loss: 0.1819 - val_accuracy: 0.5273 - val_loss: 1.9584\n",
      "Epoch 105/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.9270 - loss: 0.1893 - val_accuracy: 0.5227 - val_loss: 1.8720\n",
      "Epoch 106/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.9246 - loss: 0.2022 - val_accuracy: 0.5182 - val_loss: 1.9496\n",
      "Epoch 107/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 528ms/step - accuracy: 0.9486 - loss: 0.1424 - val_accuracy: 0.5091 - val_loss: 1.9090\n",
      "Epoch 108/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 532ms/step - accuracy: 0.9342 - loss: 0.1713 - val_accuracy: 0.5364 - val_loss: 1.9378\n",
      "Epoch 109/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 523ms/step - accuracy: 0.9450 - loss: 0.1538 - val_accuracy: 0.5182 - val_loss: 2.1264\n",
      "Epoch 110/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 523ms/step - accuracy: 0.9354 - loss: 0.1753 - val_accuracy: 0.5000 - val_loss: 2.0211\n",
      "Epoch 111/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 521ms/step - accuracy: 0.9486 - loss: 0.1558 - val_accuracy: 0.5409 - val_loss: 1.8943\n",
      "Epoch 112/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.9486 - loss: 0.1397 - val_accuracy: 0.5045 - val_loss: 2.1466\n",
      "Epoch 113/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 526ms/step - accuracy: 0.9426 - loss: 0.1439 - val_accuracy: 0.4955 - val_loss: 2.0679\n",
      "Epoch 114/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.9593 - loss: 0.1369 - val_accuracy: 0.4955 - val_loss: 2.1122\n",
      "Epoch 115/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 518ms/step - accuracy: 0.9557 - loss: 0.1318 - val_accuracy: 0.5000 - val_loss: 2.1041\n",
      "Epoch 116/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 522ms/step - accuracy: 0.9569 - loss: 0.1151 - val_accuracy: 0.5136 - val_loss: 2.2020\n",
      "Epoch 117/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 519ms/step - accuracy: 0.9545 - loss: 0.1133 - val_accuracy: 0.5045 - val_loss: 2.1560\n",
      "Epoch 118/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 519ms/step - accuracy: 0.9342 - loss: 0.1664 - val_accuracy: 0.5000 - val_loss: 2.0184\n",
      "Epoch 119/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 577ms/step - accuracy: 0.9533 - loss: 0.1386 - val_accuracy: 0.5136 - val_loss: 2.0227\n",
      "Epoch 120/120\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 552ms/step - accuracy: 0.9653 - loss: 0.1221 - val_accuracy: 0.5364 - val_loss: 1.9829\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=120,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    class_weight=class_weights,\n",
    "    # callbacks=[early_stop, lr_scheduler]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
